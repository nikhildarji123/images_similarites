{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142ce8ce-84c5-4052-9591-3738093899c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1301d33f-374a-48ed-96a3-51d83d10f02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8617cedfb1464b42b2118bc395779efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), FileUpload(value=(), accept='imag…"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import FileUpload, VBox, Button\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def load_and_detect_faces_from_bytes(image_bytes):\n",
    "    \"\"\"Load an image from bytes and detect faces.\"\"\"\n",
    "    image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "    np_image = np.array(image)\n",
    "    face_locations = face_recognition.face_locations(np_image)\n",
    "    face_landmarks = face_recognition.face_landmarks(np_image)\n",
    "    return np_image, face_locations, face_landmarks\n",
    "\n",
    "def compare_features(features1, features2):\n",
    "    \"\"\"Compare two sets of facial features.\"\"\"\n",
    "    similarity_scores = {}\n",
    "    for feature in features1.keys():\n",
    "        if feature in features2:\n",
    "            # Compute similarity score based on Euclidean distance\n",
    "            f1 = np.array(features1[feature])\n",
    "            f2 = np.array(features2[feature])\n",
    "            score = 1 - np.linalg.norm(f1 - f2) / max(np.linalg.norm(f1), np.linalg.norm(f2))\n",
    "            similarity_scores[feature] = max(score, 0)  # Ensure non-negative similarity\n",
    "        else:\n",
    "            similarity_scores[feature] = 0  # Feature missing in one face\n",
    "    return similarity_scores\n",
    "\n",
    "def draw_landmarks(image, landmarks, color=(0, 255, 0)):\n",
    "    \"\"\"Draw facial landmarks on the image.\"\"\"\n",
    "    for feature, points in landmarks.items():\n",
    "        for point in points:\n",
    "            cv2.circle(image, tuple(point), 2, color, -1)\n",
    "    return image\n",
    "\n",
    "def handle_uploaded_files(file1, file2):\n",
    "    \"\"\"Process uploaded files.\"\"\"\n",
    "    img1, face1_locations, face1_landmarks = load_and_detect_faces_from_bytes(file1)\n",
    "    img2, face2_locations, face2_landmarks = load_and_detect_faces_from_bytes(file2)\n",
    "\n",
    "    if face1_landmarks and face2_landmarks:\n",
    "        features1 = face1_landmarks[0]\n",
    "        features2 = face2_landmarks[0]\n",
    "        \n",
    "        # Compare features\n",
    "        similarity_scores = compare_features(features1, features2)\n",
    "        overall_score = np.mean(list(similarity_scores.values()))\n",
    "\n",
    "        # Draw landmarks\n",
    "        annotated_img1 = draw_landmarks(img1.copy(), features1)\n",
    "        annotated_img2 = draw_landmarks(img2.copy(), features2)\n",
    "\n",
    "        # Display the images with annotations\n",
    "        plt.figure(figsize=(15, 7))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(annotated_img1)\n",
    "        plt.title(\"Image 1\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(annotated_img2)\n",
    "        plt.title(\"Image 2\")\n",
    "        plt.show()\n",
    "\n",
    "        # Print the similarity scores\n",
    "        print(\"Feature-wise Similarity Scores:\")\n",
    "        for feature, score in similarity_scores.items():\n",
    "            print(f\"{feature.capitalize()}: {score:.2f}\")\n",
    "        print(f\"Overall Similarity Score: {overall_score:.2f}\")\n",
    "    else:\n",
    "        print(\"Face not detected in one or both images.\")\n",
    "\n",
    "# Create file upload widgets\n",
    "upload1 = FileUpload(accept=\"image/*\", multiple=False)\n",
    "upload2 = FileUpload(accept=\"image/*\", multiple=False)\n",
    "\n",
    "def on_compare_clicked(_):\n",
    "    \"\"\"Handle compare button click.\"\"\"\n",
    "    if upload1.value and upload2.value:\n",
    "        file1 = list(upload1.value.values())[0]['content']\n",
    "        file2 = list(upload2.value.values())[0]['content']\n",
    "        handle_uploaded_files(file1, file2)\n",
    "    else:\n",
    "        print(\"Please upload two images.\")\n",
    "\n",
    "# Create a button for comparison\n",
    "compare_button = Button(description=\"Compare Faces\")\n",
    "compare_button.on_click(on_compare_clicked)\n",
    "\n",
    "# Display the widgets\n",
    "VBox([upload1, upload2, compare_button])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c29e2f72-cb7e-4177-ab2c-c679b61a8cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fde39b6e184db68f5abc9b2c5fdc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), FileUpload(value=(), accept='imag…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import FileUpload, VBox, Button, Output\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Create an output widget for displaying results\n",
    "output = Output()\n",
    "\n",
    "def load_and_detect_faces_from_bytes(image_bytes):\n",
    "    \"\"\"Load an image from bytes and detect faces.\"\"\"\n",
    "    image = Image.open(BytesIO(image_bytes)).convert('RGB')\n",
    "    np_image = np.array(image)\n",
    "    face_locations = face_recognition.face_locations(np_image)\n",
    "    face_landmarks = face_recognition.face_landmarks(np_image)\n",
    "    return np_image, face_locations, face_landmarks\n",
    "\n",
    "def compare_features(features1, features2):\n",
    "    \"\"\"Compare two sets of facial features.\"\"\"\n",
    "    similarity_scores = {}\n",
    "    for feature in features1.keys():\n",
    "        if feature in features2:\n",
    "            # Compute similarity score based on Euclidean distance\n",
    "            f1 = np.array(features1[feature])\n",
    "            f2 = np.array(features2[feature])\n",
    "            score = 1 - np.linalg.norm(f1 - f2) / max(np.linalg.norm(f1), np.linalg.norm(f2))\n",
    "            similarity_scores[feature] = max(score, 0)  # Ensure non-negative similarity\n",
    "        else:\n",
    "            similarity_scores[feature] = 0  # Feature missing in one face\n",
    "    return similarity_scores\n",
    "\n",
    "def annotate_image_with_similarity(image, similarity_scores):\n",
    "    \"\"\"Annotate the image with feature similarity ranges.\"\"\"\n",
    "    annotated_image = image.copy()\n",
    "    y_offset = 30  # Starting position for text\n",
    "    for feature, score in similarity_scores.items():\n",
    "        text = f\"{feature.capitalize()}: {score:.2f}\"\n",
    "        cv2.putText(annotated_image, text, (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        y_offset += 30\n",
    "    return annotated_image\n",
    "\n",
    "def create_comparison_matrix(similarity_scores):\n",
    "    \"\"\"Create a detailed comparison matrix from similarity scores.\"\"\"\n",
    "    features = list(similarity_scores.keys())\n",
    "    scores = list(similarity_scores.values())\n",
    "    comparison_matrix = pd.DataFrame({\"Feature\": features, \"Similarity Score\": scores})\n",
    "    return comparison_matrix\n",
    "\n",
    "def handle_uploaded_files(file1, file2):\n",
    "    \"\"\"Process uploaded files.\"\"\"\n",
    "    img1, face1_locations, face1_landmarks = load_and_detect_faces_from_bytes(file1)\n",
    "    img2, face2_locations, face2_landmarks = load_and_detect_faces_from_bytes(file2)\n",
    "\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if face1_landmarks and face2_landmarks:\n",
    "            features1 = face1_landmarks[0]\n",
    "            features2 = face2_landmarks[0]\n",
    "            \n",
    "            # Compare features\n",
    "            similarity_scores = compare_features(features1, features2)\n",
    "            overall_score = np.mean(list(similarity_scores.values()))\n",
    "\n",
    "            # Annotate images with similarity ranges\n",
    "            annotated_img1 = annotate_image_with_similarity(img1, similarity_scores)\n",
    "            annotated_img2 = annotate_image_with_similarity(img2, similarity_scores)\n",
    "\n",
    "            # Create and display the comparison matrix\n",
    "            comparison_matrix = create_comparison_matrix(similarity_scores)\n",
    "\n",
    "            # Display the annotated images\n",
    "            plt.figure(figsize=(15, 7))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(annotated_img1)\n",
    "            plt.title(\"Image 1 with Features\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(annotated_img2)\n",
    "            plt.title(\"Image 2 with Features\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "            # Print the similarity scores and overall score\n",
    "            print(\"Detailed Comparison Matrix:\")\n",
    "            print(comparison_matrix.to_string(index=False))\n",
    "            print(f\"\\nOverall Similarity Score: {overall_score:.2f}\")\n",
    "        else:\n",
    "            print(\"Face not detected in one or both images.\")\n",
    "\n",
    "# Create file upload widgets\n",
    "upload1 = FileUpload(accept=\"image/*\", multiple=False)\n",
    "upload2 = FileUpload(accept=\"image/*\", multiple=False)\n",
    "\n",
    "def on_compare_clicked(_):\n",
    "    \"\"\"Handle compare button click.\"\"\"\n",
    "    if upload1.value and upload2.value:\n",
    "        file1 = list(upload1.value.values())[0]['content']\n",
    "        file2 = list(upload2.value.values())[0]['content']\n",
    "        handle_uploaded_files(file1, file2)\n",
    "    else:\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            print(\"Please upload two images.\")\n",
    "\n",
    "# Create a button for comparison\n",
    "compare_button = Button(description=\"Compare Faces\")\n",
    "compare_button.on_click(on_compare_clicked)\n",
    "\n",
    "# Display the widgets and output\n",
    "VBox([upload1, upload2, compare_button, output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ee317b1-e947-4384-9afe-59ed919a0130",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.85 GiB for an array with shape (13233, 128, 128, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m images, labels, class_indices \u001b[38;5;241m=\u001b[39m load_images_from_directory(data_dir)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Normalize pixel values\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Split data into training and validation sets\u001b[39;00m\n\u001b[0;32m     38\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.85 GiB for an array with shape (13233, 128, 128, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Function to load images manually\n",
    "def load_images_from_directory(directory, target_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(directory)\n",
    "    class_indices = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                try:\n",
    "                    img = Image.open(img_path).convert('RGB')  # Load image and convert to RGB\n",
    "                    img = img.resize(target_size)  # Resize to target size\n",
    "                    images.append(np.array(img))\n",
    "                    labels.append(class_indices[class_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_path}: {e}\")\n",
    "    return np.array(images), np.array(labels), class_indices\n",
    "\n",
    "# 1. Load Dataset Manually\n",
    "data_dir = 'C:/Users/Nikhil Darji/Downloads/archive (3)/lfw-deepfunneled/lfw-deepfunneled'\n",
    "images, labels, class_indices = load_images_from_directory(data_dir)\n",
    "\n",
    "# Normalize pixel values\n",
    "images = images / 255.0\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(class_indices))\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(class_indices))\n",
    "\n",
    "# 2. Build the CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# 3. Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 4. Train the Model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "\n",
    "# 5. Save the Model\n",
    "model.save('face_recognition_model.h5')\n",
    "print(\"Model saved as face_recognition_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19144b9-edc0-482d-86d8-00400268abff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SymbolAlreadyExposedError",
     "evalue": "Symbol Zeros is already exposed as ().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_model\u001b[39m\u001b[38;5;124m'\u001b[39m, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\__init__.py:478\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;66;03m# Do an eager load for Keras' code so that any function/method that needs to\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;66;03m# happen at load time will trigger, eg registration of optimizers in the\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# SavedModel registry.\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# See b/196254385 for more details.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m   \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    480\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\condaenv\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\applications\\convnext.py:28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\backend.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_coordinator_utils \u001b[38;5;28;01mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor_api \u001b[38;5;28;01mas\u001b[39;00m dtensor\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\keras_tensor.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_identity\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m structure\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\__init__.py:20\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Public Keras utilities.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Serialization related\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_object\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserialization_lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialize_keras_object\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobject_registration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomObjectScope\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\saving\\serialization_lib.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m object_registration\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_tf_saved_model_scope\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\utils.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_contextlib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CallFunctionSpec\n\u001b[0;32m     32\u001b[0m training_lib \u001b[38;5;241m=\u001b[39m LazyLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_lib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mglobals\u001b[39m(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.src.engine.training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muse_wrapped_call\u001b[39m(\n\u001b[0;32m     36\u001b[0m     layer, call_fn, call_spec, default_training_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, return_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     37\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\utils\\layer_utils.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\initializers\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minitializers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers_v1\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization \u001b[38;5;28;01mas\u001b[39;00m legacy_serialization\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\initializers\\initializers_v1.py:32\u001b[0m\n\u001b[0;32m     29\u001b[0m _v1_glorot_uniform_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_uniform_initializer\n\u001b[0;32m     30\u001b[0m _v1_glorot_normal_initializer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mglorot_normal_initializer\n\u001b[1;32m---> 32\u001b[0m \u001b[43mkeras_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.Zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.initializers.zeros\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_v1_zeros_initializer\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Ones\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.ones\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     36\u001b[0m     _v1_ones_initializer\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m keras_export(v1\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.Constant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.initializers.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m])(\n\u001b[0;32m     39\u001b[0m     _v1_constant_initializer\n\u001b[0;32m     40\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\tf_export.py:348\u001b[0m, in \u001b[0;36mapi_export.__call__\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    345\u001b[0m   \u001b[38;5;28mdelattr\u001b[39m(undecorated_f, api_names_attr_v1)\n\u001b[0;32m    347\u001b[0m _, undecorated_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(func)\n\u001b[1;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mundecorated_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_names_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attr(undecorated_func, api_names_attr_v1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names_v1)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_names:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\tf_export.py:364\u001b[0m, in \u001b[0;36mapi_export.set_attr\u001b[1;34m(self, func, api_names_attr, names)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_names_attr \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[0;32m    363\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_multiple_exports:\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SymbolAlreadyExposedError(\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is already exposed as \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    366\u001b[0m         (func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(func, api_names_attr)))  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28msetattr\u001b[39m(func, api_names_attr, names)\n",
      "\u001b[1;31mSymbolAlreadyExposedError\u001b[0m: Symbol Zeros is already exposed as ()."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('facenet', custom_objects=None, compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5287bd-d97b-4b45-9289-37aee35c9de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
