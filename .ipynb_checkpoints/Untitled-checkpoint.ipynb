{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17370dcc-7b43-4bd1-a7ba-df44b7da706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7899fe00-2837-4f17-aaea-7722201d46f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41528569094879086\n",
      "Faces are of the same person.\n"
     ]
    }
   ],
   "source": [
    "def getFace(img):\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "    return face_detector(img, 1)[0]\n",
    "\n",
    "def encodeFace(image):\n",
    "    face_location = getFace(image)\n",
    "    pose_predictor = dlib.shape_predictor(\"C:/Users/Nikhil Darji/Downloads/shape_predictor_68_face_landmarks_GTX.dat/shape_predictor_68_face_landmarks_GTX.dat\")\n",
    "    face_landmarks = pose_predictor(image, face_location)\n",
    "    face_encoder = dlib.face_recognition_model_v1(\"C:/Users/Nikhil Darji/Downloads/dlib_face_recognition_resnet_model_v1/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "    face = dlib.get_face_chip(image, face_landmarks)\n",
    "    encodings = np.array(face_encoder.compute_face_descriptor(face))\n",
    "    return encodings\n",
    "\n",
    "def getSimilarity(image1, image2):\n",
    "    face1_embeddings = encodeFace(image1)\n",
    "    face2_embeddings = encodeFace(image2)\n",
    "    return np.linalg.norm(face1_embeddings-face2_embeddings)\n",
    "\n",
    "img1 = cv2.imread(\"C:/Users/Nikhil Darji/Downloads/archive (3)/lfw-deepfunneled/lfw-deepfunneled/Zoran_Djindjic/Zoran_Djindjic_0003.jpg\")\n",
    "img2 = cv2.imread(\"C:/Users/Nikhil Darji/Downloads/archive (3)/lfw-deepfunneled/lfw-deepfunneled/Zoran_Djindjic/Zoran_Djindjic_0001.jpg\")\n",
    "\n",
    "distance = getSimilarity(img1, img2)\n",
    "print(distance)\n",
    "if distance < .6:\n",
    "    print(\"Faces are of the same person.\")\n",
    "else:\n",
    "    print(\"Faces are of different people.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9bc38a8-a32a-413d-b3f5-314f7a05b29f",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m img2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(img2, (\u001b[38;5;241m600\u001b[39m, \u001b[38;5;241m600\u001b[39m))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Run similarity analysis\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m feature_similarities, overall_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mget_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Print similarity matrix\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSimilarity Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 71\u001b[0m, in \u001b[0;36mget_similarity\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m     68\u001b[0m feature_similarities \u001b[38;5;241m=\u001b[39m compute_feature_similarity(landmarks1, landmarks2, image1, image2)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# Display feature annotations\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m \u001b[43mvisualize_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandmarks1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImage 1 Features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m visualize_features(image2\u001b[38;5;241m.\u001b[39mcopy(), landmarks2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage 2 Features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Output results\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 53\u001b[0m, in \u001b[0;36mvisualize_features\u001b[1;34m(image, landmarks, title)\u001b[0m\n\u001b[0;32m     51\u001b[0m         point \u001b[38;5;241m=\u001b[39m (landmarks\u001b[38;5;241m.\u001b[39mpart(i)\u001b[38;5;241m.\u001b[39mx, landmarks\u001b[38;5;241m.\u001b[39mpart(i)\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     52\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mcircle(image, point, \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load pre-trained models\n",
    "pose_predictor = dlib.shape_predictor(\"C:/Users/Nikhil Darji/Downloads/shape_predictor_68_face_landmarks_GTX.dat/shape_predictor_68_face_landmarks_GTX.dat\")\n",
    "face_encoder = dlib.face_recognition_model_v1(\"C:/Users/Nikhil Darji/Downloads/dlib_face_recognition_resnet_model_v1/dlib_face_recognition_resnet_model_v1.dat\")\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Define facial regions based on landmarks\n",
    "FEATURE_REGIONS = {\n",
    "    \"eyes\": list(range(36, 48)),       # Eye region (36-47)\n",
    "    \"nose\": list(range(27, 36)),      # Nose region (27-35)\n",
    "    \"mouth\": list(range(48, 68)),     # Mouth region (48-67)\n",
    "    \"jawline\": list(range(0, 17))     # Jawline (0-16)\n",
    "}\n",
    "\n",
    "# Detect face and extract landmarks\n",
    "def get_face_landmarks(image):\n",
    "    faces = face_detector(image, 1)\n",
    "    if len(faces) == 0:\n",
    "        raise ValueError(\"No face detected in the image.\")\n",
    "    face_location = faces[0]\n",
    "    landmarks = pose_predictor(image, face_location)\n",
    "    return face_location, landmarks\n",
    "\n",
    "# Encode face\n",
    "def encode_face(image, landmarks):\n",
    "    aligned_face = dlib.get_face_chip(image, landmarks)\n",
    "    encodings = np.array(face_encoder.compute_face_descriptor(aligned_face))\n",
    "    return encodings\n",
    "\n",
    "# Compute feature-wise similarity\n",
    "def compute_feature_similarity(landmarks1, landmarks2, image1, image2):\n",
    "    similarities = {}\n",
    "    for feature, indices in FEATURE_REGIONS.items():\n",
    "        feature_points1 = np.array([[landmarks1.part(i).x, landmarks1.part(i).y] for i in indices])\n",
    "        feature_points2 = np.array([[landmarks2.part(i).x, landmarks2.part(i).y] for i in indices])\n",
    "        # Normalize points to account for size differences\n",
    "        norm_feature_points1 = feature_points1 - feature_points1.mean(axis=0)\n",
    "        norm_feature_points2 = feature_points2 - feature_points2.mean(axis=0)\n",
    "        similarity = np.linalg.norm(norm_feature_points1 - norm_feature_points2)\n",
    "        similarities[feature] = similarity\n",
    "    return similarities\n",
    "\n",
    "# Visualize feature annotations\n",
    "def visualize_features(image, landmarks, title):\n",
    "    for feature, indices in FEATURE_REGIONS.items():\n",
    "        for i in indices:\n",
    "            point = (landmarks.part(i).x, landmarks.part(i).y)\n",
    "            cv2.circle(image, point, 2, (0, 255, 0), -1)\n",
    "    cv2.imshow(title, image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Main function\n",
    "def get_similarity(image1, image2):\n",
    "    \n",
    "    # Detect landmarks\n",
    "    landmarks1 = get_face_landmarks(image1)\n",
    "    landmarks2 = get_face_landmarks(image2)\n",
    "    \n",
    "    # Compute overall encodings\n",
    "    encodings1 = encode_face(image1, landmarks1)\n",
    "    encodings2 = encode_face(image2, landmarks2)\n",
    "    overall_similarity = np.linalg.norm(encodings1 - encodings2)\n",
    "    \n",
    "    # Compute feature-wise similarities\n",
    "    feature_similarities = compute_feature_similarity(landmarks1, landmarks2, image1, image2)\n",
    "    \n",
    "    # Display feature annotations\n",
    "    visualize_features(image1.copy(), landmarks1, \"Image 1 Features\")\n",
    "    visualize_features(image2.copy(), landmarks2, \"Image 2 Features\")\n",
    "    \n",
    "    # Output results\n",
    "    print(\"Feature-Wise Similarity:\")\n",
    "    for feature, similarity in feature_similarities.items():\n",
    "        print(f\"{feature.capitalize()}: {similarity:.2f}\")\n",
    "    print(f\"Overall Similarity: {overall_similarity:.2f}\")\n",
    "    \n",
    "    return feature_similarities, overall_similarity\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread(\"C:/Users/Nikhil Darji/Downloads/archive (3)/lfw-deepfunneled/lfw-deepfunneled/Zoran_Djindjic/Zoran_Djindjic_0003.jpg\")\n",
    "img2 = cv2.imread(\"C:/Users/Nikhil Darji/Downloads/archive (3)/lfw-deepfunneled/lfw-deepfunneled/Zoran_Djindjic/Zoran_Djindjic_0001.jpg\")\n",
    "\n",
    "# Resize images for consistency\n",
    "img1 = cv2.resize(img1, (600, 600))\n",
    "img2 = cv2.resize(img2, (600, 600))\n",
    "\n",
    "# Run similarity analysis\n",
    "feature_similarities, overall_similarity = get_similarity(img1, img2)\n",
    "\n",
    "# Print similarity matrix\n",
    "print(\"\\nSimilarity Matrix:\")\n",
    "print(feature_similarities)\n",
    "if overall_similarity < 0.6:\n",
    "    print(\"Faces are of the same person.\")\n",
    "else:\n",
    "    print(\"Faces are of different people.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904be975-fd9b-412a-870e-2ed71d48203b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
